{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/michaelcai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from TweetDataset import TweetDataset\n",
    "from vocab import VocabEntry\n",
    "\n",
    "#from gensim.models import word2vec\n",
    "\n",
    "SEED = 1234\n",
    "UNK = '<unk>'\n",
    "PAD = '<pad>'\n",
    "\n",
    "TWEET_LEN = 20\n",
    "EMBED_LEN = 300\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "DATA_FOLDER = '~/Local Documents/CS230/Project/Twitter-Sentiment/data/Data-mini/'\n",
    "\n",
    "train_data = pd.read_csv(DATA_FOLDER + 'train_mini.csv', encoding = 'latin-1')\n",
    "train_n = train_data.shape[0]\n",
    "#print (train_data)\n",
    "\n",
    "dev_data = pd.read_csv(DATA_FOLDER + 'dev_mini.csv', encoding = 'latin-1')\n",
    "dev_n = dev_data.shape[0]\n",
    "#print (dev_data)\n",
    "\n",
    "test_data = pd.read_csv(DATA_FOLDER + 'test_mini.csv', encoding = 'latin-1')\n",
    "test_n = test_data.shape[0]\n",
    "#print (test_data)\n",
    "\n",
    "dataset = pd.concat([train_data, dev_data, test_data])\n",
    "dataset_n = dataset.shape[0]\n",
    "#print (dataset)\n",
    "\n",
    "# Get ground truth x and y values\n",
    "train_x_raw = train_data.loc[:][\"Content\"]\n",
    "train_y = [0.0 if y == 0 else 1.0 for y in train_data.loc[:][\"Pos_Neg\"]]\n",
    "#print (train_y)\n",
    "\n",
    "dev_x_raw = dev_data.loc[:][\"Content\"]\n",
    "dev_y = [0.0 if y == 0 else 1.0 for y in dev_data.loc[:][\"Pos_Neg\"]]\n",
    "#print (dev_y)\n",
    "\n",
    "test_x_raw = test_data.loc[:][\"Content\"]\n",
    "test_y = [0.0 if y == 0 else 1.0 for y in test_data.loc[:][\"Pos_Neg\"]]\n",
    "#print (test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load character embeddings from pretrained embeddings file char-embeddings.txt, courtesy github user minimaxir\n",
    "char_vectors = {}\n",
    "i = 0\n",
    "for line in open('./data/char-embeddings.txt').readlines():\n",
    "    sp = line.split()\n",
    "    if len(sp) == 0: continue\n",
    "    if i == 32: \n",
    "        char_vectors['\\n'] = [float(x) for x in sp]\n",
    "    elif i == 35: \n",
    "        char_vectors[' '] = [float(x) for x in sp]\n",
    "    else: \n",
    "        char_vectors[sp[0]] = [float(x) for x in sp[1:]]\n",
    "    i += 1\n",
    "    \n",
    "# print (char_vectors)\n",
    "# print (len(char_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Y': 0, 'F': 1, 'd': 2, 'N': 3, 'h': 4, '(': 5, 'C': 6, 'w': 7, '@': 8, 'V': 9, 'z': 10, 'Z': 11, 'e': 12, 'i': 13, 'y': 14, 'T': 15, 'q': 16, '+': 17, 'O': 18, 'l': 19, ']': 20, '8': 21, '[': 22, 'u': 23, \"'\": 24, 'H': 25, '.': 26, '}': 27, 'f': 28, ';': 29, '|': 30, 'M': 31, '\\n': 32, '*': 33, 'c': 34, ' ': 35, '\"': 36, '/': 37, '7': 38, 'A': 39, ')': 40, 'D': 41, 'S': 42, 'o': 43, '5': 44, 'x': 45, 'R': 46, 'W': 47, 'Q': 48, '&': 49, '6': 50, '!': 51, '?': 52, '9': 53, 'K': 54, 'U': 55, 't': 56, 'P': 57, 'g': 58, '3': 59, 's': 60, 'J': 61, 'I': 62, 'B': 63, '#': 64, '^': 65, '0': 66, 'E': 67, 'p': 68, 'r': 69, '_': 70, 'k': 71, 'm': 72, ',': 73, '4': 74, 'v': 75, 'G': 76, 'n': 77, 'a': 78, 'X': 79, '2': 80, 'L': 81, '1': 82, '~': 83, '%': 84, '-': 85, '{': 86, 'j': 87, '$': 88, ':': 89, 'b': 90, '<unk>': 91, '<pad>': 92}\n"
     ]
    }
   ],
   "source": [
    "# Generate char IDs from full dataset\n",
    "\n",
    "char2id = {}\n",
    "\n",
    "for w in char_vectors:\n",
    "    char2id[w] = len(char2id)\n",
    "\n",
    "char2id[UNK] = len(char2id)\n",
    "char2id[PAD] = len(char2id)\n",
    "\n",
    "PAD_IDX = len(char2id) - 1\n",
    "\n",
    "print (char2id)\n",
    "\n",
    "ve = VocabEntry()\n",
    "ve.char2id = char2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(examples):\n",
    "    vec_examples = []\n",
    "    for ex in examples:\n",
    "        #print (ex)\n",
    "        sentence = [w for w in ex.strip().split()]\n",
    "#         for w in word_tokenize(ex):\n",
    "#             if w in string.punctuation:\n",
    "#                 continue\n",
    "#             sentence.append(w)\n",
    "        vec_examples.append(sentence)\n",
    "    return vec_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TweetDataset.TweetDataset object at 0x10d8e83c8>\n"
     ]
    }
   ],
   "source": [
    "# Vectorize train, dev, and test sets and convert to TweetDataset objects\n",
    "\n",
    "#train_x = ve.to_input_tensor_char(vectorize(train_x_raw), torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "#dev_x = ve.to_input_tensor_char(vectorize(dev_x_raw), torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "#test_x = ve.to_input_tensor_char(vectorize(test_x_raw), torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "#print(dev_x.shape)\n",
    "\n",
    "train_dataset = TweetDataset(train_x_raw, train_y)\n",
    "dev_dataset = TweetDataset(dev_x_raw, dev_y)\n",
    "test_dataset = TweetDataset(test_x_raw, test_y)\n",
    "print (train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build embeddings matrix\n",
    "\n",
    "embeddings_matrix = np.asarray(np.random.normal(0, 0.9, (len(char2id), EMBED_LEN)), dtype='float32')\n",
    "\n",
    "for char in char2id:\n",
    "    i = char2id[char]\n",
    "    if char in char_vectors:\n",
    "        embeddings_matrix[i] = char_vectors[char]\n",
    "\n",
    "# print (embeddings_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, embeddings, n_filters, filter_sizes, output_dim, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
    "        #torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embeddings))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.convs = nn.ModuleList([nn.Conv1d(in_channels=EMBED_LEN, out_channels=n_filters, kernel_size=(fs,embeddings.shape[1])) for fs in filter_sizes])\n",
    "        \n",
    "        for conv in self.convs:\n",
    "            torch.nn.init.xavier_uniform_(conv.weight)\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes)*n_filters, output_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print (x.shape)\n",
    "        # x.shape = (sent_len, batch_size, word_len)\n",
    "        \n",
    "        #x = [sent len, batch size]\n",
    "        \n",
    "#         x = x.permute(1, 0)\n",
    "                \n",
    "#         #x = [batch size, sent len]\n",
    "        \n",
    "        embedded = self.embedding(x)\n",
    "        print (embedded.shape)\n",
    "                \n",
    "#         #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "#         embedded = embedded.unsqueeze(1)\n",
    "        \n",
    "#         #embedded = [batch size, 1, sent len, emb dim]\n",
    "        \n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
    "            \n",
    "#         #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\n",
    "        \n",
    "#         pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "#         #pooled_n = [batch size, n_filters]\n",
    "        \n",
    "#         cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "\n",
    "#         #cat = [batch size, n_filters * len(filter_sizes)]\n",
    "            \n",
    "#         return self.fc(cat)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN(nn.Module):\n",
    "#     def __init__(self, embeddings, num_filters, k = 5, stride = 1, dropout = 0.5):\n",
    "#         \"\"\" Initialize a CNN network with a kernel of size k,  \"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.input_size = embeddings.shape[1]\n",
    "#         self.num_filters = num_filters\n",
    "#         self.k = k\n",
    "#         self.stride = stride\n",
    "        \n",
    "#         self.embedding = nn.Embedding(embeddings.shape[0], embeddings.shape[1])\n",
    "#         #torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "#         self.embedding.weight = nn.Parameter(torch.tensor(embeddings))\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        \n",
    "#         self.conv = nn.Conv1d(in_channels = embeddings.shape[1], out_channels = num_filters, kernel_size = k, bias = True)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "#         #self.pool = nn.MaxPool1d(kernel_size = k, stride = stride)\n",
    "\n",
    "#     def forward(self, x, print_sizes = False) -> torch.Tensor:\n",
    "#         \"\"\" Input x of size (max_sent_len, batch_size, max_word_length) and output of size [batchsize, embed_size] \"\"\"\n",
    "#         #x = x.permute(1, 3, 0, 2)\n",
    "#         x_emb = self.embedding(x).permute(0, 1, 3, 2)\n",
    "        \n",
    "#         cnn_output = torch.stack([my_conv.forward(sent) for sent in x_emb])\n",
    "\n",
    "#         x_conv = self.relu(self.conv(x_emb))\n",
    "#         if print_sizes: print (x_conv.shape)\n",
    "\n",
    "#         x_pool, x_pool_indices = torch.max(x_conv, dim = 2)\n",
    "#         # print (x_pool)\n",
    "#         if print_sizes: print(x_pool.shape)\n",
    "\n",
    "#         print (x_pool.shape)\n",
    "#         return x_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_filters = 100\n",
    "filter_sizes = [1, 2, 3, 4]\n",
    "output_dim = 1\n",
    "dropout = 0.5\n",
    "\n",
    "CNN_model = CNN(embeddings_matrix, n_filters, filter_sizes, output_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "   # print (rounded_preds)\n",
    "   # print (y)\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum()/len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for batchnum, batch in enumerate(train_loader):\n",
    "        #print (\"Training on batch #\" + str(batchnum))\n",
    "#         print (batch)\n",
    "        #train_x = torch.stack(batch['content'])\n",
    "        train_x = ve.to_input_tensor_char(batch['content'], device)\n",
    "        print (train_x.shape)\n",
    "        #print (train_x.shape)\n",
    "        train_y = batch['label'].float()\n",
    "        #train_y = batch['label'].long()\n",
    "        if train_x.shape[1] == 1: continue\n",
    "        #print (train_y.view(-1).shape)\n",
    "\n",
    "        predictions = model.forward(train_x).squeeze(1)\n",
    "        #print (predictions.shape)\n",
    "        loss = criterion(predictions, train_y)\n",
    "        # print (loss)\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "        acc = binary_accuracy(predictions, train_y)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dev_loader, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batchnum, batch in enumerate(dev_loader):\n",
    "            dev_x = torch.stack(batch['content'])\n",
    "            #print (train_x)\n",
    "            dev_y = batch['label'].float()\n",
    "            \n",
    "            \n",
    "            predictions = model(dev_x).squeeze(1)\n",
    "            print (torch.round(torch.sigmoid(predictions)))\n",
    "            \n",
    "            loss = criterion(predictions, dev_y)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, dev_y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(dev_loader), epoch_acc / len(dev_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 128, 21])\n",
      "torch.Size([21, 128, 21, 300])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [100, 300, 1, 300], expected input[21, 128, 21, 300] to have 300 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f7c624fc7762>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-af49759b6d5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#print (train_y.view(-1).shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;31m#print (predictions.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-996225aeb315>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         #embedded = [batch size, 1, sent len, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#         #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-996225aeb315>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         #embedded = [batch size, 1, sent len, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mconved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m#         #conv_n = [batch size, n_filters, sent len - filter_sizes[n]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 187\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [100, 300, 1, 300], expected input[21, 128, 21, 300] to have 300 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "optimizer = optim.Adam(CNN_model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "CNN_model = CNN_model.to(device)\n",
    "\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                      batch_size=128,\n",
    "                      shuffle=True,\n",
    "                      num_workers=4\n",
    "                     # pin_memory=True # CUDA only\n",
    "                     )\n",
    "    \n",
    "dev_loader = DataLoader(dev_dataset,\n",
    "                  batch_size=128,\n",
    "                  shuffle=False,\n",
    "                  num_workers=4\n",
    "                 # pin_memory=True # CUDA only\n",
    "                 )\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    train_loss, train_acc = train(CNN_model, train_loader, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(CNN_model, dev_loader, criterion, device)\n",
    "    \n",
    "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}% |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
