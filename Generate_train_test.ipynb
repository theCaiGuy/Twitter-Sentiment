{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# from sklearn.cross_validation import train_test_split - deprecated\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_data_path = '~/Local Documents/CS230/Project/Twitter-Sentiment/data/training-full.csv'\n",
    "partial_data_path = './data/training-full.csv'\n",
    "\n",
    "total_size = sum(1 for line in open(partial_data_path, encoding = 'latin-1')) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini training data set of 10000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pos_Neg          ID                          Date     QUERY  \\\n",
      "0            0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1            0  1467853356  Mon Apr 06 22:30:54 PDT 2009  NO_QUERY   \n",
      "2            0  1467894600  Mon Apr 06 22:41:51 PDT 2009  NO_QUERY   \n",
      "3            0  1467932208  Mon Apr 06 22:52:25 PDT 2009  NO_QUERY   \n",
      "4            0  1467972262  Mon Apr 06 23:03:39 PDT 2009  NO_QUERY   \n",
      "5            0  1468007877  Mon Apr 06 23:13:57 PDT 2009  NO_QUERY   \n",
      "6            0  1468047066  Mon Apr 06 23:26:06 PDT 2009  NO_QUERY   \n",
      "7            0  1468085048  Mon Apr 06 23:37:52 PDT 2009  NO_QUERY   \n",
      "8            0  1468121466  Mon Apr 06 23:49:56 PDT 2009  NO_QUERY   \n",
      "9            0  1468155926  Tue Apr 07 00:01:16 PDT 2009  NO_QUERY   \n",
      "10           0  1468192521  Tue Apr 07 00:13:02 PDT 2009  NO_QUERY   \n",
      "11           0  1468226377  Tue Apr 07 00:24:32 PDT 2009  NO_QUERY   \n",
      "12           0  1468262100  Tue Apr 07 00:36:46 PDT 2009  NO_QUERY   \n",
      "13           0  1468298918  Tue Apr 07 00:49:44 PDT 2009  NO_QUERY   \n",
      "14           0  1468336500  Tue Apr 07 01:03:03 PDT 2009  NO_QUERY   \n",
      "15           0  1468371395  Tue Apr 07 01:15:42 PDT 2009  NO_QUERY   \n",
      "16           0  1468401268  Tue Apr 07 01:26:36 PDT 2009  NO_QUERY   \n",
      "17           0  1468440198  Tue Apr 07 01:40:56 PDT 2009  NO_QUERY   \n",
      "18           0  1468470368  Tue Apr 07 01:52:04 PDT 2009  NO_QUERY   \n",
      "19           0  1468504014  Tue Apr 07 02:04:24 PDT 2009  NO_QUERY   \n",
      "20           0  1468543053  Tue Apr 07 02:18:49 PDT 2009  NO_QUERY   \n",
      "21           0  1468575832  Tue Apr 07 02:30:32 PDT 2009  NO_QUERY   \n",
      "22           0  1468617899  Tue Apr 07 02:45:41 PDT 2009  NO_QUERY   \n",
      "23           0  1468649524  Tue Apr 07 02:57:11 PDT 2009  NO_QUERY   \n",
      "24           0  1468686594  Tue Apr 07 03:09:58 PDT 2009  NO_QUERY   \n",
      "25           0  1468721137  Tue Apr 07 03:21:55 PDT 2009  NO_QUERY   \n",
      "26           0  1468755779  Tue Apr 07 03:33:42 PDT 2009  NO_QUERY   \n",
      "27           0  1468791642  Tue Apr 07 03:45:25 PDT 2009  NO_QUERY   \n",
      "28           0  1468833927  Tue Apr 07 03:58:41 PDT 2009  NO_QUERY   \n",
      "29           0  1468873358  Tue Apr 07 04:10:37 PDT 2009  NO_QUERY   \n",
      "...        ...         ...                           ...       ...   \n",
      "9971         4  2192357003  Tue Jun 16 06:54:56 PDT 2009  NO_QUERY   \n",
      "9972         4  2192397932  Tue Jun 16 06:58:47 PDT 2009  NO_QUERY   \n",
      "9973         4  2192425187  Tue Jun 16 07:01:09 PDT 2009  NO_QUERY   \n",
      "9974         4  2192514568  Tue Jun 16 07:09:03 PDT 2009  NO_QUERY   \n",
      "9975         4  2192559582  Tue Jun 16 07:12:59 PDT 2009  NO_QUERY   \n",
      "9976         4  2192584392  Tue Jun 16 07:15:13 PDT 2009  NO_QUERY   \n",
      "9977         4  2192628539  Tue Jun 16 07:19:08 PDT 2009  NO_QUERY   \n",
      "9978         4  2192673182  Tue Jun 16 07:23:05 PDT 2009  NO_QUERY   \n",
      "9979         4  2192722706  Tue Jun 16 07:27:24 PDT 2009  NO_QUERY   \n",
      "9980         4  2192768974  Tue Jun 16 07:31:22 PDT 2009  NO_QUERY   \n",
      "9981         4  2192811085  Tue Jun 16 07:35:01 PDT 2009  NO_QUERY   \n",
      "9982         4  2192839605  Tue Jun 16 07:37:33 PDT 2009  NO_QUERY   \n",
      "9983         4  2192886098  Tue Jun 16 07:41:36 PDT 2009  NO_QUERY   \n",
      "9984         4  2192935901  Tue Jun 16 07:45:55 PDT 2009  NO_QUERY   \n",
      "9985         4  2192961558  Tue Jun 16 07:48:07 PDT 2009  NO_QUERY   \n",
      "9986         4  2193007920  Tue Jun 16 07:52:05 PDT 2009  NO_QUERY   \n",
      "9987         4  2193053613  Tue Jun 16 07:55:59 PDT 2009  NO_QUERY   \n",
      "9988         4  2193082128  Tue Jun 16 07:58:23 PDT 2009  NO_QUERY   \n",
      "9989         4  2193123166  Tue Jun 16 08:01:44 PDT 2009  NO_QUERY   \n",
      "9990         4  2193179229  Tue Jun 16 08:06:14 PDT 2009  NO_QUERY   \n",
      "9991         4  2193190935  Tue Jun 16 08:07:12 PDT 2009  NO_QUERY   \n",
      "9992         4  2193254134  Tue Jun 16 08:12:22 PDT 2009  NO_QUERY   \n",
      "9993         4  2193304392  Tue Jun 16 08:16:31 PDT 2009  NO_QUERY   \n",
      "9994         4  2193322665  Tue Jun 16 08:18:02 PDT 2009  NO_QUERY   \n",
      "9995         4  2193373009  Tue Jun 16 08:22:10 PDT 2009  NO_QUERY   \n",
      "9996         4  2193427329  Tue Jun 16 08:26:39 PDT 2009  NO_QUERY   \n",
      "9997         4  2193454592  Tue Jun 16 08:28:53 PDT 2009  NO_QUERY   \n",
      "9998         4  2193503480  Tue Jun 16 08:32:48 PDT 2009  NO_QUERY   \n",
      "9999         4  2193552024  Tue Jun 16 08:36:44 PDT 2009  NO_QUERY   \n",
      "10000        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
      "\n",
      "                  User                                            Content  \n",
      "0      _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1             dbmendel  Picked Mich St to win it all from the get go. ...  \n",
      "2               dreaaa  throat is closing up and i had some string che...  \n",
      "3            rachelgab  If he doesn't get better in a few days, he cou...  \n",
      "4        Smith_Cameron  @hillary006 I'm sure everyone has ruined my gi...  \n",
      "5               John2x            my little pinky finger hurts so much..   \n",
      "6            dianapwns           @alexbigman you left without saying hi!   \n",
      "7             policano                    @hutsoncap  everything alright?  \n",
      "8          tominlumban  Yo jimo i cant talk on aim anymore, its glitch...  \n",
      "9              Jordyss  Didn't make it by here today.   They are sayin...  \n",
      "10      catherinestack                      @laurenlenewx awww i'm sorry   \n",
      "11           KristenCB  Goodnight everyone. Well I'm not feeling much ...  \n",
      "12             Fatty_D  @KellyShibari i thought i saw you there! you w...  \n",
      "13            xdokkenx  @mileycyrus I would too if it meant spending a...  \n",
      "14          bethasaurr  The one day i really need to go into school an...  \n",
      "15          tlelover91       Stephen just left,  i miss him sooo much....  \n",
      "16     soapdishsailing  I'm having a panic attack, so I can't sleep. D...  \n",
      "17     courtniecupcake  @Heromancer come back to orlando again sooon! ...  \n",
      "18             jj_tins                                    Deadline ahead   \n",
      "19       sparksthetoby                              @marissamonotony why   \n",
      "20            alunjohn  @Claire_S Will you be videoing or streaming or...  \n",
      "21      RedVelvetHeart  just been given ma marching orders, gotta go d...  \n",
      "22         jaredgunter        Up since 3:00. Going to be a looooong day.   \n",
      "23        lewisholland                    i need something big to happen   \n",
      "24       DivasMistress  @nikkiwoods Exactamundo!!! For some reason I t...  \n",
      "25        Pitstopbunny  @edibow haha, I have snot power too......1 wee...  \n",
      "26           rpecknold  Going deaf in my right ear. Too many feedback ...  \n",
      "27            FenOswin  @Schofe Dunno who is there with you, but she's...  \n",
      "28       swimmingfishy  Going to school and enjoying my last day as a ...  \n",
      "29          jerryfetus  I hate the V plotarc on True Blood  that poor ...  \n",
      "...                ...                                                ...  \n",
      "9971      gracelkinney                         @dannygokey Good morning!   \n",
      "9972       ktkeroscene                         @dannykurily welcome home   \n",
      "9973             RayYo  @jasonstoltzfus Ah gotcha-still cool! they're ...  \n",
      "9974          _alover_  @Rachael90210 day's going great thanx  course ...  \n",
      "9975            yogilo  @EliciaKoay you went overboard for the girl's ...  \n",
      "9976            shae75                  @Foxy_HotSawce good morning love   \n",
      "9977      NiqueyAlston  @Amazing_stephy um uh duh dnt think i wld kno ...  \n",
      "9978       1ChoSenOne8  This Morning I woke up feeling like money, I j...  \n",
      "9979       IdaBergdahl     @lighttrickphoto Coool, so u r from Finland ?   \n",
      "9980               snh  @rachbarnhart I have plenty of opinions that I...  \n",
      "9981          lori1329  @RecipeGirl My MIL has made that before. Oh my...  \n",
      "9982          Bthnycks  @hobnobsftww_  oo paramore are bringing out a ...  \n",
      "9983       Dianagonher                           @bigwormy good and you?   \n",
      "9984         MikeTreat          @PreciousGemGem thanks! will investigate   \n",
      "9985       andrewsmhay  @leune I tried changing the &lt;x&gt;100&lt;/x...  \n",
      "9986        bofranklin  Christ, it's sticky today... Taking a stroll h...  \n",
      "9987       jimwolffman  @colinhewitt Not yet..  Had to put together an...  \n",
      "9988       pshhitscaty  @Littlehotrod  yeah its just me ill be in play...  \n",
      "9989         MegRaiano  @Larry_Keigwin I can't wait for your classes a...  \n",
      "9990              jmt1           hey it's Jeff  http://aweber.com/b/1huHV  \n",
      "9991           twitleb               @UxSoup Soup you already confirmed!   \n",
      "9992       dennis_luis  @mikasounds if you like to support talented yo...  \n",
      "9993         karebelle  realizing you were WRONG can be humbling. but ...  \n",
      "9994    diegolikecrazy  @MariaLKanellis true, true, also gets you into...  \n",
      "9995     xxYOitsALEXxx  http://twitpic.com/7ham4 - i know now what is ...  \n",
      "9996         whipzilla  - had a great time with some of the best peopl...  \n",
      "9997             FFang  @Tyrese4ReaL Tyreseee, when you're heading to ...  \n",
      "9998          JConnell  @theokk don't know what you could possibly mea...  \n",
      "9999           bdottie          What a pretty day  &quot;Just smile&quot;  \n",
      "10000   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
      "\n",
      "[10001 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_n = 160\n",
    "train_skip = [x for x in range(1, total_size) if x % train_n != 0]\n",
    "train_data = pd.read_csv(full_data_path, skiprows=train_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "print (train_data)\n",
    "train_data.to_csv('train_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini dev data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_n = 1600\n",
    "dev_skip = [x for x in range(0, total_size) if (x + 10) % dev_n != 0]\n",
    "#print (dev_skip)\n",
    "dev_data = pd.read_csv(full_data_path, skiprows=dev_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "#print (dev_data)\n",
    "\n",
    "for i in range(dev_data.shape[0]):\n",
    "    if (train_data['Content'] == dev_data.loc[i]['Content']).any():\n",
    "        dev_data = dev_data.drop([i], axis=0)\n",
    "        \n",
    "dev_data.to_csv('dev_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini test data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = 3200\n",
    "test_skip = [x for x in range(0, total_size) if (x + 15) % test_n != 0]\n",
    "test_data = pd.read_csv(full_data_path, skiprows=test_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "# print (test_data)\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    if (train_data['Content'] == test_data.loc[i]['Content']).any():\n",
    "        test_data = test_data.drop([i], axis=0)\n",
    "\n",
    "test_data.to_csv('test_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
