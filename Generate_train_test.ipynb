{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "# from sklearn.cross_validation import train_test_split - deprecated\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_data_path = '~/Local Documents/CS230/Project/Twitter-Sentiment/data/training-full.csv'\n",
    "partial_data_path = './data/training-full.csv'\n",
    "\n",
    "total_size = sum(1 for line in open(partial_data_path, encoding = 'latin-1')) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini training data set of 10000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pos_Neg          ID                          Date     QUERY  \\\n",
      "0            0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1            0  1467815988  Mon Apr 06 22:21:09 PDT 2009  NO_QUERY   \n",
      "2            0  1467823851  Mon Apr 06 22:23:09 PDT 2009  NO_QUERY   \n",
      "3            0  1467836500  Mon Apr 06 22:26:28 PDT 2009  NO_QUERY   \n",
      "4            0  1467841832  Mon Apr 06 22:27:55 PDT 2009  NO_QUERY   \n",
      "5            0  1467853356  Mon Apr 06 22:30:54 PDT 2009  NO_QUERY   \n",
      "6            0  1467859820  Mon Apr 06 22:32:36 PDT 2009  NO_QUERY   \n",
      "7            0  1467871661  Mon Apr 06 22:35:41 PDT 2009  NO_QUERY   \n",
      "8            0  1467876652  Mon Apr 06 22:37:03 PDT 2009  NO_QUERY   \n",
      "9            0  1467882491  Mon Apr 06 22:38:37 PDT 2009  NO_QUERY   \n",
      "10           0  1467894600  Mon Apr 06 22:41:51 PDT 2009  NO_QUERY   \n",
      "11           0  1467899753  Mon Apr 06 22:43:18 PDT 2009  NO_QUERY   \n",
      "12           0  1467909222  Mon Apr 06 22:45:53 PDT 2009  NO_QUERY   \n",
      "13           0  1467917177  Mon Apr 06 22:48:08 PDT 2009  NO_QUERY   \n",
      "14           0  1467926632  Mon Apr 06 22:50:51 PDT 2009  NO_QUERY   \n",
      "15           0  1467932208  Mon Apr 06 22:52:25 PDT 2009  NO_QUERY   \n",
      "16           0  1467943526  Mon Apr 06 22:55:40 PDT 2009  NO_QUERY   \n",
      "17           0  1467949681  Mon Apr 06 22:57:27 PDT 2009  NO_QUERY   \n",
      "18           0  1467953733  Mon Apr 06 22:58:37 PDT 2009  NO_QUERY   \n",
      "19           0  1467965994  Mon Apr 06 23:01:56 PDT 2009  NO_QUERY   \n",
      "20           0  1467972262  Mon Apr 06 23:03:39 PDT 2009  NO_QUERY   \n",
      "21           0  1467982077  Mon Apr 06 23:06:29 PDT 2009  NO_QUERY   \n",
      "22           0  1467986889  Mon Apr 06 23:07:54 PDT 2009  NO_QUERY   \n",
      "23           0  1467995216  Mon Apr 06 23:10:17 PDT 2009  NO_QUERY   \n",
      "24           0  1468000948  Mon Apr 06 23:11:55 PDT 2009  NO_QUERY   \n",
      "25           0  1468007877  Mon Apr 06 23:13:57 PDT 2009  NO_QUERY   \n",
      "26           0  1468017259  Mon Apr 06 23:16:45 PDT 2009  NO_QUERY   \n",
      "27           0  1468023868  Mon Apr 06 23:18:48 PDT 2009  NO_QUERY   \n",
      "28           0  1468033983  Mon Apr 06 23:21:57 PDT 2009  NO_QUERY   \n",
      "29           0  1468038893  Mon Apr 06 23:23:33 PDT 2009  NO_QUERY   \n",
      "...        ...         ...                           ...       ...   \n",
      "49971        4  2193344006  Tue Jun 16 08:19:48 PDT 2009  NO_QUERY   \n",
      "49972        4  2193345339  Tue Jun 16 08:19:56 PDT 2009  NO_QUERY   \n",
      "49973        4  2193346991  Tue Jun 16 08:20:03 PDT 2009  NO_QUERY   \n",
      "49974        4  2193371250  Tue Jun 16 08:22:01 PDT 2009  NO_QUERY   \n",
      "49975        4  2193373009  Tue Jun 16 08:22:10 PDT 2009  NO_QUERY   \n",
      "49976        4  2193374881  Tue Jun 16 08:22:19 PDT 2009  NO_QUERY   \n",
      "49977        4  2193402232  Tue Jun 16 08:24:36 PDT 2009  NO_QUERY   \n",
      "49978        4  2193403814  Tue Jun 16 08:24:44 PDT 2009  NO_QUERY   \n",
      "49979        4  2193404869  Tue Jun 16 08:24:49 PDT 2009  NO_QUERY   \n",
      "49980        4  2193427329  Tue Jun 16 08:26:39 PDT 2009  NO_QUERY   \n",
      "49981        4  2193428354  Tue Jun 16 08:26:45 PDT 2009  NO_QUERY   \n",
      "49982        4  2193450427  Tue Jun 16 08:28:32 PDT 2009  NO_QUERY   \n",
      "49983        4  2193452183  Tue Jun 16 08:28:41 PDT 2009  NO_QUERY   \n",
      "49984        4  2193453445  Tue Jun 16 08:28:47 PDT 2009  NO_QUERY   \n",
      "49985        4  2193454592  Tue Jun 16 08:28:53 PDT 2009  NO_QUERY   \n",
      "49986        4  2193475408  Tue Jun 16 08:30:32 PDT 2009  NO_QUERY   \n",
      "49987        4  2193476829  Tue Jun 16 08:30:39 PDT 2009  NO_QUERY   \n",
      "49988        4  2193478813  Tue Jun 16 08:30:48 PDT 2009  NO_QUERY   \n",
      "49989        4  2193502163  Tue Jun 16 08:32:41 PDT 2009  NO_QUERY   \n",
      "49990        4  2193503480  Tue Jun 16 08:32:48 PDT 2009  NO_QUERY   \n",
      "49991        4  2193525430  Tue Jun 16 08:34:35 PDT 2009  NO_QUERY   \n",
      "49992        4  2193526931  Tue Jun 16 08:34:42 PDT 2009  NO_QUERY   \n",
      "49993        4  2193528475  Tue Jun 16 08:34:50 PDT 2009  NO_QUERY   \n",
      "49994        4  2193550768  Tue Jun 16 08:36:38 PDT 2009  NO_QUERY   \n",
      "49995        4  2193552024  Tue Jun 16 08:36:44 PDT 2009  NO_QUERY   \n",
      "49996        4  2193553464  Tue Jun 16 08:36:51 PDT 2009  NO_QUERY   \n",
      "49997        4  2193575004  Tue Jun 16 08:38:38 PDT 2009  NO_QUERY   \n",
      "49998        4  2193576573  Tue Jun 16 08:38:46 PDT 2009  NO_QUERY   \n",
      "49999        4  2193578151  Tue Jun 16 08:38:54 PDT 2009  NO_QUERY   \n",
      "50000        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
      "\n",
      "                  User                                            Content  \n",
      "0      _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1             merisssa  thought sleeping in was an option tomorrow but...  \n",
      "2             ericg622  I had such a nice day. Too bad the rain comes ...  \n",
      "3       natalieantipas  so rylee,grace...wana go steve's party or not?...  \n",
      "4               bgoers                                       I'm so cold   \n",
      "5             dbmendel  Picked Mich St to win it all from the get go. ...  \n",
      "6        msbutt3rfly14                        spencer is not a good guy.   \n",
      "7             ciairuhh  I miss you twitter. My phone broke, now I'm us...  \n",
      "8        SupernovaGirl  @burgaw Ooooooh! *sealclap* See, I download sh...  \n",
      "9       Stereo_Skyline  @ThaStevieG but what I really want is my old b...  \n",
      "10              dreaaa  throat is closing up and i had some string che...  \n",
      "11          Sheezy3380                   New Testament Test at 9:30 am     \n",
      "12              LAbite  Pepperoni rolls in L.A.?: I called Valentino's...  \n",
      "13            nchokkan  @KishoreK this is strange, illegal torrents av...  \n",
      "14     kailashvasupati  Dammit, episode 3 of Kings won't play for some...  \n",
      "15           rachelgab  If he doesn't get better in a few days, he cou...  \n",
      "16            javajive  @pratama Same iMac came out $320 more in Indon...  \n",
      "17         harishanker               @sasii I know exactly how you feel!   \n",
      "18            MonikkaB  @paul_e_wog Wait...is it a game or just episod...  \n",
      "19         lanaveenker  @AmandaEnglund Sorry to hear about your loss. ...  \n",
      "20       Smith_Cameron  @hillary006 I'm sure everyone has ruined my gi...  \n",
      "21            mcdoogie  Spring break is here at last, but no one is he...  \n",
      "22            BrianG2k                      @lilbucknuts41 not an option   \n",
      "23        Reynaga12345                        Still doing my homework!!!   \n",
      "24         Hanster7705                     i feel sick  too much icecream  \n",
      "25              John2x            my little pinky finger hurts so much..   \n",
      "26             mishkia  aaaaand back to my literature review  At least...  \n",
      "27          ChrisMoody  One of the hardest thing with this schedule, n...  \n",
      "28     patrick_ritchie                       @featherinair call me back.   \n",
      "29      DangeresqueBen          @therealnph Twitter hates us both then.    \n",
      "...                ...                                                ...  \n",
      "49971      Amanda_Mosh  @kruss87 I know  I got it a few days ago haha ...  \n",
      "49972     spacegrace19  helllllo twitter! #iremember playing #haveyoue...  \n",
      "49973          flaka09  i miss aric i dont want to but i do , jimmy is...  \n",
      "49974   adambuckeridge  @spiralhosting Cool , I look forward to it  Lo...  \n",
      "49975    xxYOitsALEXxx  http://twitpic.com/7ham4 - i know now what is ...  \n",
      "49976        MrsLoulou              @phdinparenting It was a great post!   \n",
      "49977        krystlerb  @TANGG GT was a good movie...although I spent ...  \n",
      "49978       lyddiechoi  is off to lesson then ortho appt.  Dreading to...  \n",
      "49979       nut_cookie              Getting offline! Take care everyone.   \n",
      "49980        whipzilla  - had a great time with some of the best peopl...  \n",
      "49981      Bloodl3tt3r  Not a problem @rafaelladm  Thanks â« http://b...  \n",
      "49982      HelloGracey  Exploring the world of Twitter   Listening to ...  \n",
      "49983            WiiDS  And PEGI Wins. The Fear Spider Will Be Staying...  \n",
      "49984   camilamariotto         @alicebarrooss happy birthday, alice!!!!!   \n",
      "49985            FFang  @Tyrese4ReaL Tyreseee, when you're heading to ...  \n",
      "49986       SamNiley11                                  @francii_ me too   \n",
      "49987     Septimus1812  @radagast22 It's not the 'nillas I worry about...  \n",
      "49988         davoloid  @theskink And in car?  On street via Mobile?  ...  \n",
      "49989       JohnWeston          http://twitpic.com/7jomc - Party invites   \n",
      "49990         JConnell  @theokk don't know what you could possibly mea...  \n",
      "49991  MandeeLeigh1911  Watching pride and prejudice again &lt;3 then ...  \n",
      "49992   Killer_Burrito  Okay so the plan is to go to hot topic and buy...  \n",
      "49993            Shash                        @linksforluv  you betcha!!   \n",
      "49994        mlvlatina                   @asimkovsky thanks for the info   \n",
      "49995          bdottie          What a pretty day  &quot;Just smile&quot;  \n",
      "49996     UrBaN_eLySsE  @FoSho174 LMAO @ capture the flag..bless their...  \n",
      "49997  say_my_name_too                 @say_my_name TRAITOR!!!! love you   \n",
      "49998            Emm94  Is back from getting the new jonas brothers cd...  \n",
      "49999  victoriaquinnxo   done la examen! easy peasy  so proud of myself!!  \n",
      "50000   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
      "\n",
      "[50001 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_n = 32\n",
    "train_skip = [x for x in range(1, total_size) if x % train_n != 0]\n",
    "train_data = pd.read_csv(full_data_path, skiprows=train_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "print (train_data)\n",
    "train_data.to_csv('train_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini dev data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_n = 1600\n",
    "dev_skip = [x for x in range(0, total_size) if (x + 10) % dev_n != 0]\n",
    "#print (dev_skip)\n",
    "dev_data = pd.read_csv(full_data_path, skiprows=dev_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "#print (dev_data)\n",
    "\n",
    "for i in range(dev_data.shape[0]):\n",
    "    if (train_data['Content'] == dev_data.loc[i]['Content']).any():\n",
    "        dev_data = dev_data.drop([i], axis=0)\n",
    "        \n",
    "dev_data.to_csv('dev_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini test data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = 3200\n",
    "test_skip = [x for x in range(0, total_size) if (x + 15) % test_n != 0]\n",
    "test_data = pd.read_csv(full_data_path, skiprows=test_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "# print (test_data)\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    if (train_data['Content'] == test_data.loc[i]['Content']).any():\n",
    "        test_data = test_data.drop([i], axis=0)\n",
    "\n",
    "test_data.to_csv('test_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
