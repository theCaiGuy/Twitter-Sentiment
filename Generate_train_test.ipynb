{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split - deprecated\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "full_data_path = '~/Local Documents/CS230/Project/Twitter-Sentiment/data/training-full.csv'\n",
    "partial_data_path = './data/training-full.csv'\n",
    "\n",
    "total_size = sum(1 for line in open(partial_data_path, encoding = 'latin-1')) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini training data set of 10000 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Pos_Neg          ID                          Date     QUERY  \\\n",
      "0            0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
      "1            0  1467839737  Mon Apr 06 22:27:21 PDT 2009  NO_QUERY   \n",
      "2            0  1467873004  Mon Apr 06 22:36:03 PDT 2009  NO_QUERY   \n",
      "3            0  1467901188  Mon Apr 06 22:43:43 PDT 2009  NO_QUERY   \n",
      "4            0  1467932208  Mon Apr 06 22:52:25 PDT 2009  NO_QUERY   \n",
      "5            0  1467963715  Mon Apr 06 23:01:18 PDT 2009  NO_QUERY   \n",
      "6            0  1467992207  Mon Apr 06 23:09:26 PDT 2009  NO_QUERY   \n",
      "7            0  1468019453  Mon Apr 06 23:17:25 PDT 2009  NO_QUERY   \n",
      "8            0  1468047066  Mon Apr 06 23:26:06 PDT 2009  NO_QUERY   \n",
      "9            0  1468075671  Mon Apr 06 23:34:52 PDT 2009  NO_QUERY   \n",
      "10           0  1468106399  Mon Apr 06 23:44:57 PDT 2009  NO_QUERY   \n",
      "11           0  1468129897  Mon Apr 06 23:52:43 PDT 2009  NO_QUERY   \n",
      "12           0  1468155926  Tue Apr 07 00:01:16 PDT 2009  NO_QUERY   \n",
      "13           0  1468185887  Tue Apr 07 00:10:51 PDT 2009  NO_QUERY   \n",
      "14           0  1468209388  Tue Apr 07 00:18:42 PDT 2009  NO_QUERY   \n",
      "15           0  1468235599  Tue Apr 07 00:27:43 PDT 2009  NO_QUERY   \n",
      "16           0  1468262100  Tue Apr 07 00:36:46 PDT 2009  NO_QUERY   \n",
      "17           0  1468290857  Tue Apr 07 00:46:52 PDT 2009  NO_QUERY   \n",
      "18           0  1468319163  Tue Apr 07 00:57:02 PDT 2009  NO_QUERY   \n",
      "19           0  1468342622  Tue Apr 07 01:05:16 PDT 2009  NO_QUERY   \n",
      "20           0  1468371395  Tue Apr 07 01:15:42 PDT 2009  NO_QUERY   \n",
      "21           0  1468392589  Tue Apr 07 01:23:27 PDT 2009  NO_QUERY   \n",
      "22           0  1468419545  Tue Apr 07 01:33:19 PDT 2009  NO_QUERY   \n",
      "23           0  1468445455  Tue Apr 07 01:42:55 PDT 2009  NO_QUERY   \n",
      "24           0  1468470368  Tue Apr 07 01:52:04 PDT 2009  NO_QUERY   \n",
      "25           0  1468495130  Tue Apr 07 02:01:15 PDT 2009  NO_QUERY   \n",
      "26           0  1468522016  Tue Apr 07 02:10:57 PDT 2009  NO_QUERY   \n",
      "27           0  1468550790  Tue Apr 07 02:21:35 PDT 2009  NO_QUERY   \n",
      "28           0  1468575832  Tue Apr 07 02:30:32 PDT 2009  NO_QUERY   \n",
      "29           0  1468604810  Tue Apr 07 02:40:55 PDT 2009  NO_QUERY   \n",
      "...        ...         ...                           ...       ...   \n",
      "13305        4  2192720251  Tue Jun 16 07:27:11 PDT 2009  NO_QUERY   \n",
      "13306        4  2192745446  Tue Jun 16 07:29:25 PDT 2009  NO_QUERY   \n",
      "13307        4  2192770352  Tue Jun 16 07:31:29 PDT 2009  NO_QUERY   \n",
      "13308        4  2192811085  Tue Jun 16 07:35:01 PDT 2009  NO_QUERY   \n",
      "13309        4  2192837781  Tue Jun 16 07:37:23 PDT 2009  NO_QUERY   \n",
      "13310        4  2192861177  Tue Jun 16 07:39:27 PDT 2009  NO_QUERY   \n",
      "13311        4  2192887529  Tue Jun 16 07:41:43 PDT 2009  NO_QUERY   \n",
      "13312        4  2192935901  Tue Jun 16 07:45:55 PDT 2009  NO_QUERY   \n",
      "13313        4  2192959502  Tue Jun 16 07:47:56 PDT 2009  NO_QUERY   \n",
      "13314        4  2192984297  Tue Jun 16 07:50:05 PDT 2009  NO_QUERY   \n",
      "13315        4  2193009495  Tue Jun 16 07:52:13 PDT 2009  NO_QUERY   \n",
      "13316        4  2193053613  Tue Jun 16 07:55:59 PDT 2009  NO_QUERY   \n",
      "13317        4  2193080471  Tue Jun 16 07:58:15 PDT 2009  NO_QUERY   \n",
      "13318        4  2193106297  Tue Jun 16 08:00:21 PDT 2009  NO_QUERY   \n",
      "13319        4  2193152774  Tue Jun 16 08:04:06 PDT 2009  NO_QUERY   \n",
      "13320        4  2193179229  Tue Jun 16 08:06:14 PDT 2009  NO_QUERY   \n",
      "13321        4  2193188976  Tue Jun 16 08:07:02 PDT 2009  NO_QUERY   \n",
      "13322        4  2193223854  Tue Jun 16 08:09:55 PDT 2009  NO_QUERY   \n",
      "13323        4  2193276683  Tue Jun 16 08:14:16 PDT 2009  NO_QUERY   \n",
      "13324        4  2193304392  Tue Jun 16 08:16:31 PDT 2009  NO_QUERY   \n",
      "13325        4  2193320231  Tue Jun 16 08:17:49 PDT 2009  NO_QUERY   \n",
      "13326        4  2193346098  Tue Jun 16 08:19:59 PDT 2009  NO_QUERY   \n",
      "13327        4  2193401077  Tue Jun 16 08:24:30 PDT 2009  NO_QUERY   \n",
      "13328        4  2193427329  Tue Jun 16 08:26:39 PDT 2009  NO_QUERY   \n",
      "13329        4  2193453166  Tue Jun 16 08:28:46 PDT 2009  NO_QUERY   \n",
      "13330        4  2193477741  Tue Jun 16 08:30:43 PDT 2009  NO_QUERY   \n",
      "13331        4  2193525714  Tue Jun 16 08:34:36 PDT 2009  NO_QUERY   \n",
      "13332        4  2193552024  Tue Jun 16 08:36:44 PDT 2009  NO_QUERY   \n",
      "13333        4  2193577726  Tue Jun 16 08:38:52 PDT 2009  NO_QUERY   \n",
      "13334        4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
      "\n",
      "                  User                                            Content  \n",
      "0      _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
      "1               JenBah  Is pissed off that there's no ASBA's for a rad...  \n",
      "2             omgitsjo  I miss him.  Can't wait to celebrate the Tar H...  \n",
      "3            bonerjamz  @cococourtney i was just listening to the swee...  \n",
      "4            rachelgab  If he doesn't get better in a few days, he cou...  \n",
      "5          missmadison  @Born_4_Broadway Lost  and it was St. Ignacius...  \n",
      "6            Huddy1124  I hate converting movies just to put em on my ...  \n",
      "7              Pan_duh  @rootbeersoup Yeah. Too bad people like a cert...  \n",
      "8            dianapwns           @alexbigman you left without saying hi!   \n",
      "9            im_mature              @onlysweeter I don't know the dance.   \n",
      "10        robotwarlord  The one day I have to go to school is the same...  \n",
      "11             AMEFACE  had the worst dream abt some turd face i used ...  \n",
      "12             Jordyss  Didn't make it by here today.   They are sayin...  \n",
      "13        micahmarquis  A few catering gigs, very cool, getting ready ...  \n",
      "14            khanhlnq                 @ChauV I has so many things to do   \n",
      "15       drxgirlfriend        @imperiusrex Brahbrah. Ugh. Bed in a hour.   \n",
      "16             Fatty_D  @KellyShibari i thought i saw you there! you w...  \n",
      "17     ACTinglikeamama  @Cezzadwen I think that it's pretty standard w...  \n",
      "18              egg104  @jeffkang greeeeat but now i ate all my hard w...  \n",
      "19        supervelerey  is so 'jeles' argh.  sy pn mau jln sm kau jg. ...  \n",
      "20          tlelover91       Stephen just left,  i miss him sooo much....  \n",
      "21          SarahSaner  @mikebreed Its all up to us Mike.  I understan...  \n",
      "22              hertog  @fabianv what kind of docs? and what are you u...  \n",
      "23             sahmura  @kristenkreuk fiuhh, nice to get info from you...  \n",
      "24             jj_tins                                    Deadline ahead   \n",
      "25            carakole  @islandiva147 I sent u a tweet yesterday but I...  \n",
      "26           NusardelO  Was going to make a site updates twitter accou...  \n",
      "27           amygirl28                 has got a cold coming  how shite!!  \n",
      "28      RedVelvetHeart  just been given ma marching orders, gotta go d...  \n",
      "29       paperclipface                              Wet hair in my eyes.   \n",
      "...                ...                                                ...  \n",
      "13305         SweetGio  @OfficialTL Oh my God!!!!  We love New Moon an...  \n",
      "13306     goodtobeglad  PS just texting me (twice!) to test my fortitu...  \n",
      "13307         monmen07                 I'm so exciteeed, @ecksssy!  Haha!  \n",
      "13308         lori1329  @RecipeGirl My MIL has made that before. Oh my...  \n",
      "13309   CaityPineapple                                  @Madayar Cheers.   \n",
      "13310       hildegunni               @lasgalen I do - only takes 40 mins   \n",
      "13311       TheFamulus  @BumbleWard Could be. I never watched them. Mr...  \n",
      "13312        MikeTreat          @PreciousGemGem thanks! will investigate   \n",
      "13313     BethanieChan                        it's a beautiful day today   \n",
      "13314    StephanieLW08  @VivaMiGlam its good. funniest movie ive seen ...  \n",
      "13315     jeremiahalva     @bennyalvarado hey alchy  how's working going?  \n",
      "13316      jimwolffman  @colinhewitt Not yet..  Had to put together an...  \n",
      "13317       harmony333  I am a M I L F..dont you forget...wash it away...  \n",
      "13318      pennymoore5  @MWiesner G-L-A-D you like em! They are my fav...  \n",
      "13319        ZyonSwope  Grocery shopping! Hopefully its not 500 dollar...  \n",
      "13320             jmt1           hey it's Jeff  http://aweber.com/b/1huHV  \n",
      "13321           TC_DNB  just got back from a little shop called Electr...  \n",
      "13322        Steph2611              @bwechols getting paid is a problem?   \n",
      "13323   LauraBarcelona    @ashleytisdale niceeeee!  we miss you in spain!  \n",
      "13324        karebelle  realizing you were WRONG can be humbling. but ...  \n",
      "13325         SteveRal  getting the movie crybaby for someone that wan...  \n",
      "13326        Placehold  @JalokimGraphics lmao yeah it sounds seriously...  \n",
      "13327       vicki_anne                   is going to lay out by the pool   \n",
      "13328        whipzilla  - had a great time with some of the best peopl...  \n",
      "13329       ikeapencil           Reading avalon high! Hah, I'm surprised   \n",
      "13330      just_chalie  @Elle_333 @jenfafer midnight showing peoples, ...  \n",
      "13331  EmilyatMeritain                        @alwaysfurst See you there   \n",
      "13332          bdottie          What a pretty day  &quot;Just smile&quot;  \n",
      "13333         FrayBaby     @pokapolas love the donut and the toadstool.    \n",
      "13334   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
      "\n",
      "[13335 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "train_n = 120\n",
    "train_skip = [x for x in range(1, total_size) if x % train_n != 0]\n",
    "train_data = pd.read_csv(full_data_path, skiprows=train_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "print (train_data)\n",
    "train_data.to_csv('train_full.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini dev data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d6a6b9a673c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdev_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdev_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_datetimelike_v_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dev_n = 1600\n",
    "dev_skip = [x for x in range(0, total_size) if (x + 10) % dev_n != 0]\n",
    "#print (dev_skip)\n",
    "dev_data = pd.read_csv(full_data_path, skiprows=dev_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "#print (dev_data)\n",
    "\n",
    "for i in range(dev_data.shape[0]):\n",
    "    if (train_data['Content'] == dev_data.loc[i]['Content']).any():\n",
    "        dev_data = dev_data.drop([i], axis=0)\n",
    "        \n",
    "#dev_data.to_csv('dev_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mini test data set of 500 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = 3200\n",
    "test_skip = [x for x in range(0, total_size) if (x + 15) % test_n != 0]\n",
    "test_data = pd.read_csv(full_data_path, skiprows=test_skip, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "# print (test_data)\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    if (train_data['Content'] == test_data.loc[i]['Content']).any():\n",
    "        test_data = test_data.drop([i], axis=0)\n",
    "\n",
    "#test_data.to_csv('test_mini.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv(full_data_path, encoding = 'latin-1', names = [\"Pos_Neg\", \"ID\", \"Date\", \"QUERY\", \"User\", \"Content\"])\n",
    "\n",
    "num_neutral = 0\n",
    "for i in range(1, all_data.shape[0]):\n",
    "    if all_data.loc[i, 'Pos_Neg'] == 2:\n",
    "        num_neutral += 1\n",
    "        \n",
    "print (num_neutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
